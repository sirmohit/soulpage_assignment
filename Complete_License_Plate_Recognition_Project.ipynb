{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6404050",
   "metadata": {},
   "source": [
    "# License Plate Recognition Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1c83f7",
   "metadata": {},
   "source": [
    "\n",
    "This notebook implements the entire pipeline for license plate detection and recognition, including:\n",
    "1. **Data Loading and Preprocessing**  \n",
    "2. **YOLOv8 Model Training for License Plate Detection**  \n",
    "3. **OCR Integration for Character Recognition**  \n",
    "4. **End-to-End Pipeline Execution**  \n",
    "5. **Evaluation and Metrics**  \n",
    "\n",
    "Detailed comments are provided to help explain each part of the code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b3b7fd",
   "metadata": {},
   "source": [
    "## Step 1: Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59134a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import essential libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "from sklearn.metrics import accuracy_score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51728b4d",
   "metadata": {},
   "source": [
    "## Step 2: Load and Preprocess Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa8372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define paths to datasets\n",
    "training_data_1_path = \"path_to_training_data_1\"  # Car images with bounding boxes\n",
    "training_data_2_path = \"path_to_training_data_2\"  # Number plate images with text\n",
    "test_data_path = \"path_to_test_data\"  # Test set\n",
    "\n",
    "# Load annotations and images\n",
    "def load_data(path):\n",
    "    images = []\n",
    "    annotations = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
    "            images.append(cv2.imread(os.path.join(path, file)))\n",
    "        elif file.endswith(\".txt\"):\n",
    "            with open(os.path.join(path, file), 'r') as f:\n",
    "                annotations.append(f.read())\n",
    "    return images, annotations\n",
    "\n",
    "# Load data for each set\n",
    "train1_images, train1_annotations = load_data(training_data_1_path)\n",
    "train2_images, train2_annotations = load_data(training_data_2_path)\n",
    "test_images, test_annotations = load_data(test_data_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86abc2ea",
   "metadata": {},
   "source": [
    "## Step 3: Train YOLOv8 for License Plate Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecb3ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initializing YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')  # Using a pre-trained YOLOv8 nano model\n",
    "\n",
    "# Preparing training configuration\n",
    "# Training Set 1 is formatted in YOLO's expected structure with 'data.yaml'\n",
    "data_yaml_path = \"path_to_yolo_config.yaml\"\n",
    "\n",
    "# Train YOLO model\n",
    "model.train(data=data_yaml_path, epochs=100, imgsz=640, name=\"license_plate_detection\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dbc95c",
   "metadata": {},
   "source": [
    "## Step 4: Use EasyOCR for Character Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcdb911",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initializing EasyOCR model\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# Function to recognize text from an image\n",
    "def recognize_text(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    results = reader.readtext(image)\n",
    "    return ''.join([res[1] for res in results])  # Combining all recognized strings\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0022ca",
   "metadata": {},
   "source": [
    "## Step 5: Detection and Recognition Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535046f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combining YOLOv8 and OCR for end-to-end processing\n",
    "def detect_and_recognize(image):\n",
    "    # Detect license plates\n",
    "    results = model(image)\n",
    "    boxes = results[0].boxes.xyxy  # Extracting bounding box coordinates\n",
    "\n",
    "    # Croping detected license plates and recognizing text\n",
    "    recognized_texts = []\n",
    "    for box in boxes:\n",
    "        xmin, ymin, xmax, ymax = map(int, box)\n",
    "        cropped = image[ymin:ymax, xmin:xmax]\n",
    "        text = recognize_text(cropped)\n",
    "        recognized_texts.append(text)\n",
    "\n",
    "    return recognized_texts\n",
    "\n",
    "# Running pipeline on test images\n",
    "test_results = {}\n",
    "for idx, test_image in enumerate(test_images):\n",
    "    test_results[idx] = detect_and_recognize(test_image)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed861f0",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate the Model on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e21bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extracting ground-truth annotations for test set\n",
    "ground_truths = [ann.split('\\n') for ann in test_annotations]\n",
    "\n",
    "# Comparing with predictions and calculating accuracy\n",
    "all_predictions = []\n",
    "all_ground_truths = []\n",
    "\n",
    "for idx in range(len(test_images)):\n",
    "    all_predictions.extend(test_results[idx])  # Flatten predictions\n",
    "    all_ground_truths.extend(ground_truths[idx])  # Flatten ground truths\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(all_ground_truths, all_predictions)\n",
    "print(f\"License Plate Recognition Accuracy: {accuracy * 100:.2f}%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ef0f38",
   "metadata": {},
   "source": [
    "## Results and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fff54ed",
   "metadata": {},
   "source": [
    "\n",
    "The pipeline successfully combines YOLOv8 for license plate detection and EasyOCR for character recognition.\n",
    "The achieved accuracy on the test set is reported above.  \n",
    "Further improvements can be made by fine-tuning YOLOv8 and improving OCR integration.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
